{
 "cells": [
  {
   "source": [
    "# Speech to Text using a Raspberry Pi\n",
    "\n",
    "This lab shows how to use the [Azure Cognitive Services speech service](https://azure.microsoft.com/services/cognitive-services/speech-services/?WT.mc_id=academic-7372-jabenn) on a Raspberry Pi. You will need a Cognitive Services speech resource to use this lab, and you can find all the instructions to get set up in the [README file](https://github.com/microsoft/iot-curriculum/tree/main/labs/ai-edge/speech).\n",
    "\n",
    "This lab records 10 seconds of speech, then sends it to the Speech service to convert to text.\n",
    "\n",
    "There is currently no SDK support for this speech service on ARM32 Linux, so this lab uses the REST APIs.\n",
    "\n",
    "To use this Notebook, read each documentation cell, then select Run to run each code cell. The output of the code cells will be shown below. You can read more on running Jupyter Notebooks in the [Jupyter Notebooks documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First the options for the Speech cognitive service need to be configured.\n",
    "* Set the `KEY` variable to be the key of your speech resource.\n",
    "* Set the `ENDPOINT` variable to be the endpoint of your speech resource.\n",
    "* Set the `LANGUAGE` variable to the language you will be speaking in. You can find details on the supported langauges in the [Language and voice support for the Speech service documentation](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-7372-jabenn)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"YOUR_SPEECH_KEY\"\n",
    "ENDPOINT = \"YOUR_SPEECH_ENDPOINT\"\n",
    "LANGUAGE = \"en-US\""
   ]
  },
  {
   "source": [
    "Import some Python packages to hande the microphone, audio files and REST requests to make them available to the Python code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "source": [
    "Before audio can be captured, some configuration needs to be set up. The sample rate needs to be set to 16khz, and the sample length needs to be set to 10 seconds.\n",
    "\n",
    "> If you want to record for longer, change the value of `sample_len` to the time in seconds that you want to record for."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Speech to Text Cognitive Service API currently only supports a 16000hz samplerate\n",
    "sample_rate = 16000\n",
    "\n",
    "# Length of the audio sample in seconds\n",
    "sample_len = 10"
   ]
  },
  {
   "source": [
    "Now capture the audio. Once you start running this cell, speak into the microphone for 10 seconds."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the speech sample\n",
    "speech_sample = sd.rec(int(sample_len * sample_rate), samplerate=sample_rate, channels=1)\n",
    "\n",
    "print(\"Start speaking now!\")\n",
    "\n",
    "# Wait for the recording to stop after the specified number of seconds\n",
    "sd.wait()\n",
    "\n",
    "# Let the user know the recording is done\n",
    "print(\"Recorded!\")"
   ]
  },
  {
   "source": [
    "The speech sample now needs to be saved to disk."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of audio file to save sample\n",
    "filename = \"speech_to_text_rec.wav\"\n",
    "\n",
    "# Save speech sample as a .wav file\n",
    "write(filename, sample_rate, speech_sample)"
   ]
  },
  {
   "source": [
    "To verify everything was recorded correctly, playback the audio by using the `aplay` command line utility"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"aplay \" + filename)"
   ]
  },
  {
   "source": [
    "The endpoint that comes from the Cognitive Service is designed to issue access tokens so you can then make the relevant API call. \n",
    "\n",
    "The REST API is documented in the [Speech-to-text REST API documentation](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-speech-to-text?WT.mc_id=academic-7372-jabenn#authentication).\n",
    "\n",
    "The header passes the following:\n",
    "\n",
    "* The API Key of the speech resource\n",
    "\n",
    "The return value is an access token that lasts for 10 minutes and is used when calling the rest of the API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the request headers with the API key\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": KEY\n",
    "}\n",
    "\n",
    "# Make a POST request to the endpoint to get the token\n",
    "response = requests.post(ENDPOINT, headers=headers)\n",
    "access_token = str(response.text)"
   ]
  },
  {
   "source": [
    "Next step is to make the REST API call, uploading the file with the speech data to a URL. The URL is built by extracting the location from the API endpoint and using that to build a new URL pointing to the speech service itself.\n",
    "\n",
    "The REST API is documented in the [Speech-to-text REST API documentation](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text?WT.mc_id=academic-7372-jabenn#sample-request).\n",
    "\n",
    "The header passes the following:\n",
    "\n",
    "* The bearer token that was retrieved earlier\n",
    "* The content type as a WAV file with a sample rate of 16KHz\n",
    "\n",
    "The body of the request is the audio file that was just written.\n",
    "\n",
    "The return value is a JSON document with details on the detected speech, including the text from the speech."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location from the endpoint by removing the http protocol and getting the section before the first .\n",
    "location = ENDPOINT.split(\"//\")[-1].split(\".\")[0]\n",
    "\n",
    "# Build the URL from the location\n",
    "url = \"https://\" + location + \".stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1\"\n",
    "\n",
    "# Set the headers to include the Cognitive Services resource key\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + access_token,\n",
    "    \"Content-Type\": \"audio/wav; codecs=audio/pcm; samplerate=16000\",\n",
    "    \"Accept\": \"application/json;text/xml\"\n",
    "}\n",
    "\n",
    "# Configure the language parameter for the call\n",
    "params = {\n",
    "    \"language\": LANGUAGE\n",
    "}\n",
    "\n",
    "# Make the request passing the file as the body\n",
    "response = requests.post(url, headers=headers, params=params, data=open(filename, \"rb\"))"
   ]
  },
  {
   "source": [
    "The `response` contains the result of the speech to text call as JSON. If the call was successful, it will return an object with a `RecognitionStatus` of `Success`, and a `DisplayText` with the speech converted to text."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to JSON\n",
    "response_json = json.loads(response.text)\n",
    "\n",
    "if response_json[\"RecognitionStatus\"] == \"Success\":\n",
    "    print('Results from Speech to Text API:')\n",
    "    print(response_json['DisplayText'])\n",
    "else:\n",
    "    print(\"No speech detected\")\n",
    "    print(\"The raw response is:\")\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}